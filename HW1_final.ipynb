{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1607cd",
   "metadata": {
    "id": "ee1607cd"
   },
   "source": [
    "# Ecological RAG System ‚Äì Premium Edition üåä\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35bd35e",
   "metadata": {
    "id": "c35bd35e"
   },
   "outputs": [],
   "source": [
    "# If running on Colab, uncomment to install dependencies:\n",
    "!pip -q install gradio==4.* sentence-transformers chromadb scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66480b70",
   "metadata": {
    "id": "66480b70"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import pandas as pd\n",
    "import gdown\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87c40c8",
   "metadata": {
    "id": "a87c40c8"
   },
   "outputs": [],
   "source": [
    "# Package detection\n",
    "try:\n",
    "    import chromadb\n",
    "    CHROMADB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CHROMADB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import gradio as gr\n",
    "    GRADIO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GRADIO_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a384b8",
   "metadata": {
    "id": "56a384b8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ac5bece",
   "metadata": {
    "id": "9ac5bece"
   },
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"Lightweight vector store for when ChromaDB is unavailable\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "        self.metadatas = []\n",
    "        self.ids = []\n",
    "\n",
    "    def add(self, embeddings, documents, metadatas, ids):\n",
    "        self.embeddings.extend(embeddings)\n",
    "        self.documents.extend(documents)\n",
    "        self.metadatas.extend(metadatas)\n",
    "        self.ids.extend(ids)\n",
    "\n",
    "    def query(self, query_embeddings, n_results=5):\n",
    "        if not self.embeddings:\n",
    "            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}\n",
    "\n",
    "        similarities = cosine_similarity(query_embeddings, self.embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:n_results]\n",
    "\n",
    "        return {\n",
    "            'ids': [[self.ids[i] for i in top_indices]],\n",
    "            'documents': [[self.documents[i] for i in top_indices]],\n",
    "            'metadatas': [[self.metadatas[i] for i in top_indices]],\n",
    "            'distances': [[1 - similarities[i] for i in top_indices]]\n",
    "        }\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c447dd6c",
   "metadata": {
    "id": "c447dd6c"
   },
   "outputs": [],
   "source": [
    "class EcologicalRAG:\n",
    "    \"\"\"Main RAG system for ecological research papers\"\"\"\n",
    "\n",
    "    def __init__(self, openai_api_key=None):\n",
    "        self._initialize_components(openai_api_key)\n",
    "        self.papers = []\n",
    "        self.fitted = False\n",
    "\n",
    "    def _initialize_components(self, openai_api_key):\n",
    "        \"\"\"Initialize all system components silently\"\"\"\n",
    "        # Setup embedding model\n",
    "        if TRANSFORMERS_AVAILABLE:\n",
    "            try:\n",
    "                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "                self.use_transformers = True\n",
    "            except Exception:\n",
    "                self._setup_tfidf()\n",
    "        else:\n",
    "            self._setup_tfidf()\n",
    "\n",
    "        # Setup vector store\n",
    "        if CHROMADB_AVAILABLE:\n",
    "            try:\n",
    "                client = chromadb.Client()\n",
    "                try:\n",
    "                    self.collection = client.get_collection(\"ecological_papers\")\n",
    "                except Exception:\n",
    "                    self.collection = client.create_collection(\"ecological_papers\")\n",
    "                self.use_chromadb = True\n",
    "            except Exception:\n",
    "                self.collection = SimpleVectorStore()\n",
    "                self.use_chromadb = False\n",
    "        else:\n",
    "            self.collection = SimpleVectorStore()\n",
    "            self.use_chromadb = False\n",
    "\n",
    "        # Setup OpenAI\n",
    "        if openai_api_key and OPENAI_AVAILABLE:\n",
    "            openai.api_key = openai_api_key\n",
    "            self.use_openai = True\n",
    "        else:\n",
    "            self.use_openai = False\n",
    "\n",
    "    def _setup_tfidf(self):\n",
    "        \"\"\"Setup TF-IDF as fallback\"\"\"\n",
    "        self.use_transformers = False\n",
    "        self.tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and prepare text for processing\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s\\-\\.\\(\\)]', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_entities(self, text):\n",
    "        \"\"\"Extract ecological entities from text\"\"\"\n",
    "        entities = {'species': [], 'locations': [], 'methods': []}\n",
    "\n",
    "        # Species (binomial nomenclature)\n",
    "        species = re.findall(r'\\b[A-Z][a-z]+ [a-z]+\\b', text)\n",
    "        entities['species'] = list(set(species))[:3]\n",
    "\n",
    "        # Locations\n",
    "        locations = re.findall(\n",
    "            r'\\b(Mediterranean|Red Sea|Lake Kinneret|Eastern Mediterranean|Levantine)\\b',\n",
    "            text, re.IGNORECASE\n",
    "        )\n",
    "        entities['locations'] = list(set(locations))[:3]\n",
    "\n",
    "        # Methods\n",
    "        methods = re.findall(\n",
    "            r'\\b(PCR|DNA|sequencing|survey|analysis|modeling)\\b',\n",
    "            text, re.IGNORECASE\n",
    "        )\n",
    "        entities['methods'] = list(set(methods))[:3]\n",
    "\n",
    "        return entities\n",
    "\n",
    "    def generate_embeddings(self, texts):\n",
    "        \"\"\"Generate embeddings using available method\"\"\"\n",
    "        if self.use_transformers:\n",
    "            return self.embedding_model.encode(texts, show_progress_bar=False)\n",
    "        else:\n",
    "            if not self.fitted:\n",
    "                self.tfidf.fit(texts)\n",
    "                self.fitted = True\n",
    "            return self.tfidf.transform(texts).toarray()\n",
    "\n",
    "    def load_papers(self, papers_data):\n",
    "        \"\"\"Load papers into the RAG system\"\"\"\n",
    "        valid_papers = [p for p in papers_data if p.get('abstract', '').strip()]\n",
    "\n",
    "        if not valid_papers:\n",
    "            return False\n",
    "\n",
    "        documents, metadatas, ids = [], [], []\n",
    "\n",
    "        for i, paper in enumerate(valid_papers):\n",
    "            text = f\"{paper.get('title', '')} {paper.get('abstract', '')}\"\n",
    "            text = self.preprocess_text(text)\n",
    "\n",
    "            if len(text) < 50:\n",
    "                continue\n",
    "\n",
    "            entities = self.extract_entities(text)\n",
    "\n",
    "            metadata = {\n",
    "                'title': paper.get('title', 'Unknown'),\n",
    "                'authors': paper.get('authors', 'Unknown'),\n",
    "                'journal': paper.get('journal', 'Unknown'),\n",
    "                'year': paper.get('year', 2022),\n",
    "                'doi': paper.get('doi', ''),\n",
    "                'species': ', '.join(entities['species']),\n",
    "                'locations': ', '.join(entities['locations']),\n",
    "                'methods': ', '.join(entities['methods'])\n",
    "            }\n",
    "\n",
    "            documents.append(text)\n",
    "            metadatas.append(metadata)\n",
    "            ids.append(f\"paper_{i}\")\n",
    "\n",
    "        if not documents:\n",
    "            return False\n",
    "\n",
    "        # Generate embeddings\n",
    "        embeddings = self.generate_embeddings(documents)\n",
    "\n",
    "        # Add to vector store\n",
    "        if getattr(self, 'use_chromadb', False):\n",
    "            try:\n",
    "                self.collection.add(\n",
    "                    embeddings=embeddings.tolist(),\n",
    "                    documents=documents,\n",
    "                    metadatas=metadatas,\n",
    "                    ids=ids\n",
    "                )\n",
    "            except Exception:\n",
    "                # Fallback in case of unexpected API mismatch\n",
    "                self.collection = SimpleVectorStore()\n",
    "                self.collection.add(\n",
    "                    embeddings=embeddings,\n",
    "                    documents=documents,\n",
    "                    metadatas=metadatas,\n",
    "                    ids=ids\n",
    "                )\n",
    "        else:\n",
    "            self.collection.add(\n",
    "                embeddings=embeddings,\n",
    "                documents=documents,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "\n",
    "        self.papers = valid_papers\n",
    "        return True\n",
    "\n",
    "    def search(self, query, n_results=3):\n",
    "        \"\"\"Search for relevant papers\"\"\"\n",
    "        query_processed = self.preprocess_text(query)\n",
    "        query_embedding = self.generate_embeddings([query_processed])\n",
    "\n",
    "        if getattr(self, 'use_chromadb', False):\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=query_embedding.tolist(),\n",
    "                n_results=n_results\n",
    "            )\n",
    "        else:\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=query_embedding,\n",
    "                n_results=n_results\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _generate_openai_response(self, query, papers, search_results):\n",
    "        \"\"\"Generate response using OpenAI\"\"\"\n",
    "        context = \"\\n\\n\".join([\n",
    "            f\"Paper: {papers[i]['title']}\\n\"\n",
    "            f\"Authors: {papers[i]['authors']}\\n\"\n",
    "            f\"Content: {search_results['documents'][0][i][:400]}...\"\n",
    "            for i in range(min(len(search_results['documents'][0]), len(papers)))\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"You are an expert marine ecologist. Answer this question based on the research provided:\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Research Papers:\n",
    "{context}\n",
    "\n",
    "Provide a comprehensive answer citing the research. Focus on Mediterranean and freshwater ecosystems.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert marine and freshwater ecologist.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=800,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception:\n",
    "            return self._generate_template_response(query, papers, search_results)\n",
    "\n",
    "    def _generate_template_response(self, query, papers, search_results):\n",
    "        \"\"\"Generate template response without OpenAI\"\"\"\n",
    "        response = f\"## Research Findings for: {query}\\n\\n\"\n",
    "\n",
    "        for i, paper in enumerate(papers[:3]):\n",
    "            response += f\"### {i+1}. {paper['title']}\\n\"\n",
    "            response += f\"**Authors:** {paper['authors']}\\n\"\n",
    "            response += f\"**Journal:** {paper['journal']} ({paper['year']})\\n\"\n",
    "\n",
    "            if paper.get('species'):\n",
    "                response += f\"**Species:** {paper['species']}\\n\"\n",
    "            if paper.get('locations'):\n",
    "                response += f\"**Locations:** {paper['locations']}\\n\"\n",
    "            if paper.get('methods'):\n",
    "                response += f\"**Methods:** {paper['methods']}\\n\"\n",
    "\n",
    "            response += f\"**DOI:** {paper['doi']}\\n\\n\"\n",
    "\n",
    "        # Add summary\n",
    "        all_species = set()\n",
    "        all_locations = set()\n",
    "        for paper in papers:\n",
    "            if paper.get('species'):\n",
    "                all_species.update([s.strip() for s in paper['species'].split(',') if s.strip()])\n",
    "            if paper.get('locations'):\n",
    "                all_locations.update([l.strip() for l in paper['locations'].split(',') if l.strip()])\n",
    "\n",
    "        response += \"### Summary\\n\"\n",
    "        if all_species:\n",
    "            response += f\"**Key Species:** {', '.join(list(all_species)[:5])}\\n\"\n",
    "        if all_locations:\n",
    "            response += f\"**Study Regions:** {', '.join(list(all_locations))}\\n\"\n",
    "\n",
    "        return response\n",
    "\n",
    "    def generate_response(self, query, search_results):\n",
    "        \"\"\"Generate response based on search results\"\"\"\n",
    "        if not search_results['documents'][0]:\n",
    "            return \"No relevant papers found for your query.\"\n",
    "\n",
    "        papers = search_results['metadatas'][0]\n",
    "\n",
    "        if getattr(self, 'use_openai', False):\n",
    "            return self._generate_openai_response(query, papers, search_results)\n",
    "        else:\n",
    "            return self._generate_template_response(query, papers, search_results)\n",
    "\n",
    "    def query(self, question, n_results=5):\n",
    "        \"\"\"Main query function\"\"\"\n",
    "        search_results = self.search(question, n_results)\n",
    "        response = self.generate_response(question, search_results)\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'response': response,\n",
    "            'papers_found': len(search_results['documents'][0]),\n",
    "            'search_results': search_results\n",
    "        }\n",
    "\n",
    "    def get_status(self):\n",
    "        \"\"\"Get system status\"\"\"\n",
    "        return {\n",
    "            'vector_db': 'ChromaDB' if getattr(self, 'use_chromadb', False) else 'Simple Store',\n",
    "            'embeddings': 'Transformer' if getattr(self, 'use_transformers', False) else 'TF-IDF',\n",
    "            'generation': 'OpenAI GPT' if getattr(self, 'use_openai', False) else 'Template',\n",
    "            'papers_loaded': len(self.papers) if self.papers else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294de2b7",
   "metadata": {
    "id": "294de2b7"
   },
   "outputs": [],
   "source": [
    "#Function which is in charge of the papers used in our RAG\n",
    "def get_sample_iolr_papers():\n",
    "    return [\n",
    "       {\n",
    "    'title': 'BTEX and PAH contributions to Lake Kinneret water: a seasonal-based study of volatile and semi-volatile anthropogenic pollutants in freshwater sources',\n",
    "    'authors': 'Astrahan, P., Lupu, A., Leibovici, E., and S. Ninio.',\n",
    "    'journal': 'Environmental Science and Pollution Research',\n",
    "    'year': 2023,\n",
    "    'doi': 'https://doi.org/10.1007/s11356-023-26724-9',\n",
    "    'abstract': 'BTEX and PAH contributions to Lake Kinneret water: a seasonal-based study of volatile and semi-volatile anthropogenic pollutants in freshwater sources. Environmental Science and Pollution Research, 30(21):61145-61159'\n",
    "},\n",
    "{\n",
    "    'title': 'Sodium levels and grazing pressure shape natural communities of the intracellular pathogen Legionella',\n",
    "    'authors': 'Bergman, O., Beeri-Shlevin, Y., and S. Ninio.',\n",
    "    'journal': 'Microbiome',\n",
    "    'year': 2023,\n",
    "    'doi': 'https://doi.org/10.1186/s40168-023-01611-0',\n",
    "    'abstract': 'Sodium levels and grazing pressure shape natural communities of the intracellular pathogen Legionella. Microbiome, 11:167'\n",
    "},\n",
    "{\n",
    "    'title': 'Anthropogenic and natural disturbances along a river and its estuary alter the diversity of pathogens and antibiotic resistance mechanisms',\n",
    "    'authors': 'Rubin-Blum M., Harbuzov Z., Cohen R., and P. Astrahan.',\n",
    "    'journal': 'Science of The Total Environment',\n",
    "    'year': 2023,\n",
    "    'doi': 'https://doi.org/10.1016/j.scitotenv.2023.164108',\n",
    "    'abstract': 'Anthropogenic and natural disturbances along a river and its estuary alter the diversity of pathogens and antibiotic resistance mechanisms. Science of The Total Environment, 887:164108'\n",
    "},\n",
    "{\n",
    "    'title': 'The microbial community spatially varies during a Microcystis bloom event in Lake Kinneret',\n",
    "    'authors': 'Schweitzer-Natan, O., Ofek-Lalzar, M., Sher, D., and A. Sukenik.',\n",
    "    'journal': 'Freshwater Biology',\n",
    "    'year': 2023,\n",
    "    'doi': 'https://doi.org/10.1111/fwb.14030',\n",
    "    'abstract': 'The microbial community spatially varies during a Microcystis bloom event in Lake Kinneret. Freshwater Biology, 68(2):349-363'\n",
    "},\n",
    "{\n",
    "    'title': 'Upstream nitrogen availability determines the Microcystis salt tolerance and influences microcystins release in brackish water',\n",
    "    'authors': 'Li X., Li L., Huang Y., Wu H., Sheng S., Jiang X., Chen X., and I. Ostrovsky.',\n",
    "    'journal': 'Water Research',\n",
    "    'year': 2024,\n",
    "    'doi': 'https://doi.org/10.1016/j.watres.2024.121213',\n",
    "    'abstract': 'Upstream nitrogen availability determines the Microcystis salt tolerance and influences microcystins release in brackish water. Water Research, 252:121213'\n",
    "}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213c901",
   "metadata": {
    "id": "5213c901"
   },
   "outputs": [],
   "source": "def create_premium_interface(rag_system):\n    \"\"\"Create elegant Gradio web interface with improved dark theme\"\"\"\n\n    import gradio as gr\n\n    def query_papers(question, n_results):\n        if not question.strip():\n            return \"Please enter a research question to get started.\"\n        result = rag_system.query(question, n_results=int(n_results))\n        return f\"### ü§ñ AI Answer\\n{result['response']}\"\n\n    def get_system_metrics():\n        status = rag_system.get_status()\n        return f\"\"\"\n        **System Configuration**\n\n        Vector Database: {status['vector_db']} üóÑÔ∏è\n        Embeddings: {status['embeddings']} üîÆ\n        Generation: {status['generation']} ü§ñ\n        Papers Loaded: {status['papers_loaded']} üìö\n        \"\"\"\n\n    # Example questions\n    examples = [\n        (\"How do BTEX and PAH pollutants contaminate freshwater sources?\", 3),\n        (\"What seasonal patterns exist for volatile pollutants in Lake Kinneret?\", 3),\n        (\"How do anthropogenic disturbances affect pathogen diversity in rivers?\", 4),\n        (\"What antibiotic resistance mechanisms emerge from environmental pollution?\", 3),\n        (\"How do semi-volatile pollutants impact aquatic ecosystem health?\", 3),\n    ]\n\n    def run_example_0():\n        q, n = examples[0]\n        res = rag_system.query(q, n_results=int(n))\n        return q, int(n), res[\"response\"]\n\n    def run_example_1():\n        q, n = examples[1]\n        res = rag_system.query(q, n_results=int(n))\n        return q, int(n), res[\"response\"]\n\n    def run_example_2():\n        q, n = examples[2]\n        res = rag_system.query(q, n_results=int(n))\n        return q, int(n), res[\"response\"]\n\n    def run_example_3():\n        q, n = examples[3]\n        res = rag_system.query(q, n_results=int(n))\n        return q, int(n), res[\"response\"]\n\n    def run_example_4():\n        q, n = examples[4]\n        res = rag_system.query(q, n_results=int(n))\n        return q, int(n), res[\"response\"]\n\n    example_handlers = [run_example_0, run_example_1, run_example_2, run_example_3, run_example_4]\n\n    # --- Custom CSS ---\n    custom_css = \"\"\"\n    :root {\n        --primary-color: #2563eb;\n        --secondary-color: #1e40af;\n        --background-color: #0f172a;\n        --surface-color: #1e293b;\n        --surface-light: #334155;\n        --text-primary: #f8fafc;\n        --text-secondary: #cbd5e1;\n        --accent-color: #3b82f6;\n        --success-color: #059669;\n        --border-color: #475569;\n    }\n    .gradio-container { background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%); color: var(--text-primary); font-family: 'Inter','Segoe UI',sans-serif; min-height: 100vh; }\n    .main-header { background: rgba(30,41,59,.8); backdrop-filter: blur(20px); border-radius: 16px; padding: 2rem; margin: 1rem; box-shadow: 0 8px 32px rgba(0,0,0,.3); border: 1px solid rgba(71,85,105,.3); }\n    .query-section { background: rgba(30,41,59,.6); backdrop-filter: blur(15px); border-radius: 12px; padding: 1.5rem; box-shadow: 0 4px 20px rgba(0,0,0,.2); border: 1px solid rgba(71,85,105,.2); }\n    .response-area { background: rgba(30,41,59,.7) !important; border-radius: 12px !important; border: 1px solid rgba(71,85,105,.3) !important; box-shadow: 0 4px 20px rgba(0,0,0,.15) !important; color: var(--text-primary) !important; }\n    .status-panel { background: linear-gradient(135deg,#1e40af 0%,#3730a3 100%); border-radius: 12px; padding: 1rem; color: white; box-shadow: 0 4px 15px rgba(59,130,246,.2); border: 1px solid rgba(147,197,253,.2); }\n\n    .gradio-textbox textarea, .gradio-textbox input { background: rgba(51,65,85,.8) !important; border: 1px solid rgba(71,85,105,.4) !important; border-radius: 8px !important; color: var(--text-primary) !important; font-size: 14px !important; }\n    .gradio-textbox textarea:focus, .gradio-textbox input:focus { border-color: var(--accent-color) !important; box-shadow: 0 0 0 2px rgba(59,130,246,.2) !important; }\n    .gradio-button { background: linear-gradient(135deg,var(--primary-color) 0%,var(--secondary-color) 100%) !important; border: none !important; border-radius: 8px !important; color: white !important; font-weight: 600 !important; transition: all .3s ease !important; }\n    .gradio-button:hover { transform: translateY(-1px) !important; box-shadow: 0 6px 20px rgba(37,99,235,.3) !important; }\n    .gradio-slider input[type=\"range\"] { background: rgba(51,65,85,.8) !important; }\n    .gradio-accordion { background: rgba(30,41,59,.5) !important; border: 1px solid rgba(71,85,105,.3) !important; border-radius: 8px !important; }\n\n    .examples-grid { display: grid; grid-template-columns: 1fr; gap: .5rem; }\n    @media (min-width: 900px) { .examples-grid { grid-template-columns: 1fr 1fr; } }\n    .example-btn { text-align: left; white-space: normal; line-height: 1.3; padding: .75rem 1rem; }\n    .example-meta { opacity: .85; font-size: .9rem; }\n    .markdown-content h1, .markdown-content h2, .markdown-content h3 { color: var(--text-primary) !important; }\n    .markdown-content p { color: var(--text-secondary) !important; line-height: 1.6 !important; }\n    .gradio-label { color: var(--text-primary) !important; font-weight: 500 !important; }\n\n    /* Prompt textbox */\n    #prompt_box textarea,\n    #prompt_box input[type=\"text\"] {\n        color: black !important;\n        caret-color: black !important;\n    }\n    #prompt_box textarea::placeholder,\n    #prompt_box input[type=\"text\"]::placeholder {\n        color: #111 !important;\n        opacity: .6 !important;\n    }\n\n    /* Slider numeric input */\n    #docs_count input[type=\"number\"] {\n        color: #000 !important;\n        -webkit-text-fill-color: #000 !important;\n        caret-color: #000 !important;\n        opacity: 1 !important;\n    }\n    #docs_count input[type=\"number\"]::placeholder {\n        color: #111 !important;\n        opacity: .7 !important;\n    }\n    \"\"\"\n\n    with gr.Blocks(\n        title=\"Ecological Research Assistant\",\n        theme=gr.themes.Base(\n            primary_hue=\"blue\",\n            secondary_hue=\"slate\",\n            neutral_hue=\"slate\",\n            font=gr.themes.GoogleFont(\"Inter\")\n        ).set(\n            body_background_fill=\"#0f172a\",\n            body_text_color=\"#f8fafc\",\n            background_fill_primary=\"#1e293b\",\n            background_fill_secondary=\"#334155\",\n            border_color_primary=\"#475569\",\n            color_accent=\"#3b82f6\",\n            color_accent_soft=\"#1e40af\"\n        ),\n        css=custom_css\n    ) as interface:\n\n        with gr.Column(elem_classes=\"main-header\"):\n            gr.HTML(\"\"\"\n            <div style=\"text-align: center;\">\n                <h1 style=\"background: linear-gradient(45deg,#60a5fa,#3b82f6);\n                           -webkit-background-clip: text;\n                           -webkit-text-fill-color: transparent;\n                           font-size: 2.5rem; margin: 0; font-weight: 700;\">\n                    Ecological Research Assistant üåä\n                </h1>\n                <p style=\"font-size: 1.1rem; color: #94a3b8; margin-top: .5rem; font-weight: 400;\">\n                    AI-powered insights from IOLR marine and freshwater research\n                </p>\n            </div>\n            \"\"\")\n\n        with gr.Row():\n            with gr.Column(scale=3, elem_classes=\"query-section\"):\n                question_input = gr.Textbox(\n                    label=\"üîç Research Question\",\n                    placeholder=\"Ask about subjects in pollution that interest you\",\n                    lines=3,\n                    elem_id=\"prompt_box\",\n                )\n                with gr.Row():\n                    n_results_slider = gr.Slider(\n                        minimum=1, maximum=5, value=5, step=1,\n                        label=\"Papers to analyze üìÑ \",\n                        elem_id=\"docs_count\",\n                    )\n                    submit_btn = gr.Button(\"Analyze Research üöÄ \", variant=\"primary\")\n\n            with gr.Column(scale=1, elem_classes=\"status-panel\"):\n                system_info = gr.Markdown(get_system_metrics())\n\n        response_output = gr.Markdown(label=\"üìä Research Analysis\", elem_classes=\"response-area\", show_label=True)\n\n        with gr.Accordion(\"üí° Example Questions\", open=False):\n            gr.HTML('<div class=\"example-meta\">Try these research questions:</div>')\n            with gr.Column(elem_classes=\"examples-grid\"):\n                for i, (q, n) in enumerate(examples):\n                    btn = gr.Button(f\"üîé {q}  ¬∑  {n} papers\", elem_classes=\"example-btn\")\n                    btn.click(\n                        fn=example_handlers[i],\n                        inputs=[],\n                        outputs=[question_input, n_results_slider, response_output],\n                    )\n\n        submit_btn.click(fn=query_papers, inputs=[question_input, n_results_slider], outputs=response_output)\n        question_input.submit(fn=query_papers, inputs=[question_input, n_results_slider], outputs=response_output)\n\n    return interface"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79de5357",
   "metadata": {
    "id": "79de5357"
   },
   "outputs": [],
   "source": [
    "#Load the API key using google drive\n",
    "def initialize_system():\n",
    "    file_id = \"1aKb_3hV9XmSq1M5l4HCNgvSxarbLjb-g\"\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"openai_key.txt\", quiet=False)\n",
    "\n",
    "    with open(\"openai_key.txt\") as f:\n",
    "      api_key = f.read().strip()\n",
    "    print(\"‚úÖ Loaded key, length:\", len(api_key))\n",
    "    rag_system = EcologicalRAG(api_key)\n",
    "    sample_papers = get_sample_iolr_papers()\n",
    "    rag_system.load_papers(sample_papers)\n",
    "    return rag_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12b49089",
   "metadata": {
    "id": "12b49089"
   },
   "outputs": [],
   "source": [
    "#Find available port to run the application\n",
    "def find_available_port(start_port=7860, max_attempts=10):\n",
    "    import socket\n",
    "    for port in range(start_port, start_port + max_attempts):\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.bind(('localhost', port))\n",
    "                return port\n",
    "        except OSError:\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d55ea0a9",
   "metadata": {
    "id": "d55ea0a9"
   },
   "outputs": [],
   "source": [
    "#The main function which launches the application\n",
    "def launch_app():\n",
    "    rag_system = initialize_system()\n",
    "    if GRADIO_AVAILABLE:\n",
    "        interface = create_premium_interface(rag_system)\n",
    "        port = find_available_port()\n",
    "        if port is None:\n",
    "            interface.launch(share=True, show_error=False, quiet=True)\n",
    "        else:\n",
    "            interface.launch(share=True, server_port=port, show_error=False, quiet=True)\n",
    "    else:\n",
    "        # If gradio isn't available, just return the system for programmatic use\n",
    "        return rag_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da01dc75",
   "metadata": {
    "id": "da01dc75",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "outputId": "066beaff-f5e5-496a-e842-becf0c007782"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aKb_3hV9XmSq1M5l4HCNgvSxarbLjb-g\n",
      "To: /content/openai_key.txt\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [00:00<00:00, 69.3kB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Loaded key, length: 164\n",
      "* Running on public URL: https://06d5d876fff94667c5.gradio.live\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://06d5d876fff94667c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Run the app (uncomment to launch Gradio)\n",
    "if __name__ == \"__main__\":\n",
    "    launch_app()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}