{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Data Firebase Sync\n",
    "\n",
    "This notebook syncs sensor data from the API to Firebase Realtime Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install firebase-admin requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Firebase credentials file\n",
    "from google.colab import files\n",
    "print('Please upload your firebase_key.json file:')\n",
    "uploaded = files.upload()\n",
    "print('File uploaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import os\n",
    "\n",
    "# ============== FIREBASE INITIALIZATION ==============\n",
    "# Initialize Firebase using credentials\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate('firebase_key.json')\n",
    "    firebase_admin.initialize_app(cred, {\n",
    "        'databaseURL': 'https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/'\n",
    "    })\n",
    "    print('Firebase initialized successfully')\n",
    "else:\n",
    "    print('Firebase already initialized')\n",
    "\n",
    "# ============== API CONFIGURATION ==============\n",
    "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
    "FEED = \"json\"\n",
    "BATCH_LIMIT = 200\n",
    "EARLIEST_DATE = \"2025-10-01T00:00:00Z\"\n",
    "\n",
    "# ============== HELPER FUNCTIONS ==============\n",
    "def get_latest_timestamp_from_firebase():\n",
    "    \"\"\"Get the most recent timestamp stored in Firebase\"\"\"\n",
    "    try:\n",
    "        ref = db.reference('/sensor_data')\n",
    "        latest = ref.order_by_child('created_at').limit_to_last(1).get()\n",
    "        \n",
    "        if latest:\n",
    "            latest_key = list(latest.keys())[0]\n",
    "            return latest[latest_key]['created_at']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting latest timestamp: {e}\")\n",
    "    return None\n",
    "\n",
    "def fetch_batch(before_timestamp=None):\n",
    "    \"\"\"Fetch a batch of data from the API\"\"\"\n",
    "    params = {\n",
    "        \"feed\": FEED,\n",
    "        \"limit\": BATCH_LIMIT\n",
    "    }\n",
    "    \n",
    "    if before_timestamp:\n",
    "        params[\"before_created_at\"] = before_timestamp\n",
    "    \n",
    "    response = requests.get(f\"{BASE_URL}/history\", params=params)\n",
    "    return response.json()\n",
    "\n",
    "def save_to_firebase(data_list):\n",
    "    \"\"\"Save data to Firebase\"\"\"\n",
    "    ref = db.reference('/sensor_data')\n",
    "    \n",
    "    saved_count = 0\n",
    "    for sample in data_list:\n",
    "        timestamp_key = sample['created_at'].replace(':', '-').replace('.', '-')\n",
    "        sensor_values = json.loads(sample['value'])\n",
    "        \n",
    "        record = {\n",
    "            'created_at': sample['created_at'],\n",
    "            'temperature': sensor_values['temperature'],\n",
    "            'humidity': sensor_values['humidity'],\n",
    "            'soil': sensor_values['soil']\n",
    "        }\n",
    "        \n",
    "        ref.child(timestamp_key).set(record)\n",
    "        saved_count += 1\n",
    "        \n",
    "        if saved_count % 100 == 0:\n",
    "            print(f\"  Saved {saved_count}/{len(data_list)} records...\")\n",
    "    \n",
    "    return saved_count\n",
    "\n",
    "def download_all_data():\n",
    "    \"\"\"Download all historical data in batches\"\"\"\n",
    "    print(f\"Starting data download from now back to {EARLIEST_DATE}...\")\n",
    "    all_data = []\n",
    "    previous_oldest = None\n",
    "    \n",
    "    response = fetch_batch()\n",
    "    \n",
    "    if \"data\" not in response:\n",
    "        print(\"Error fetching initial data:\", response)\n",
    "        return []\n",
    "    \n",
    "    all_data.extend(response[\"data\"])\n",
    "    print(f\"Fetched initial {len(response['data'])} samples.\")\n",
    "    \n",
    "    batch_count = 1\n",
    "    stuck_count = 0\n",
    "    \n",
    "    while True:\n",
    "        if not all_data:\n",
    "            break\n",
    "        \n",
    "        before_timestamp = all_data[-1][\"created_at\"]\n",
    "        \n",
    "        if before_timestamp == previous_oldest:\n",
    "            stuck_count += 1\n",
    "            if stuck_count >= 2:\n",
    "                print(f\"No more older data available\")\n",
    "                break\n",
    "        else:\n",
    "            stuck_count = 0\n",
    "        \n",
    "        previous_oldest = before_timestamp\n",
    "        \n",
    "        if before_timestamp <= EARLIEST_DATE:\n",
    "            print(f\"Reached earliest date limit: {EARLIEST_DATE}\")\n",
    "            all_data = [sample for sample in all_data if sample[\"created_at\"] >= EARLIEST_DATE]\n",
    "            break\n",
    "        \n",
    "        response = fetch_batch(before_timestamp)\n",
    "        \n",
    "        if \"data\" in response and len(response[\"data\"]) > 0:\n",
    "            batch_count += 1\n",
    "            \n",
    "            filtered_batch = [sample for sample in response[\"data\"] \n",
    "                            if sample[\"created_at\"] >= EARLIEST_DATE \n",
    "                            and sample[\"created_at\"] < before_timestamp]\n",
    "            \n",
    "            if filtered_batch:\n",
    "                all_data.extend(filtered_batch)\n",
    "                print(f\"Batch {batch_count}: {len(filtered_batch)} samples. Total: {len(all_data)}\")\n",
    "                \n",
    "                if len(filtered_batch) < len(response[\"data\"]):\n",
    "                    print(f\"Reached earliest date limit\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No new data in batch\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"No more data available\")\n",
    "            break\n",
    "        \n",
    "        if batch_count > 1000:\n",
    "            print(f\"Safety limit reached\")\n",
    "            break\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def download_new_data(latest_timestamp):\n",
    "    \"\"\"Download only data newer than the latest timestamp\"\"\"\n",
    "    print(f\"Downloading data newer than {latest_timestamp}...\")\n",
    "    new_data = []\n",
    "    \n",
    "    response = fetch_batch()\n",
    "    \n",
    "    if \"data\" not in response:\n",
    "        print(\"Error fetching data:\", response)\n",
    "        return []\n",
    "    \n",
    "    for sample in response[\"data\"]:\n",
    "        if sample[\"created_at\"] > latest_timestamp:\n",
    "            new_data.append(sample)\n",
    "        else:\n",
    "            print(f\"Reached existing data at {sample['created_at']}\")\n",
    "            return new_data\n",
    "    \n",
    "    print(f\"Fetched {len(new_data)} new samples.\")\n",
    "    return new_data\n",
    "\n",
    "# ============== MAIN EXECUTION ==============\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SENSOR DATA FIREBASE SYNC\")\n",
    "    print(f\"Run time: {datetime.now().isoformat()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    latest_timestamp = get_latest_timestamp_from_firebase()\n",
    "    \n",
    "    if latest_timestamp:\n",
    "        print(f\"\\nFound existing data in Firebase.\")\n",
    "        print(f\"Latest timestamp: {latest_timestamp}\")\n",
    "        print(\"\\nFetching only new data...\")\n",
    "        \n",
    "        new_data = download_new_data(latest_timestamp)\n",
    "        \n",
    "        if new_data:\n",
    "            print(f\"\\nSaving {len(new_data)} new samples to Firebase...\")\n",
    "            saved = save_to_firebase(new_data)\n",
    "            print(f\"\\n{saved} new records saved!\")\n",
    "        else:\n",
    "            print(\"\\nNo new data. Database is up to date!\")\n",
    "    else:\n",
    "        print(\"\\nNo existing data found.\")\n",
    "        print(\"Starting full download...\\n\")\n",
    "        \n",
    "        all_data = download_all_data()\n",
    "        \n",
    "        if all_data:\n",
    "            print(f\"\\nSummary:\")\n",
    "            print(f\"  Total: {len(all_data)}\")\n",
    "            print(f\"  Earliest: {all_data[-1]['created_at']}\")\n",
    "            print(f\"  Latest: {all_data[0]['created_at']}\")\n",
    "            \n",
    "            print(f\"\\nSaving {len(all_data)} samples...\")\n",
    "            saved = save_to_firebase(all_data)\n",
    "            print(f\"\\n{saved} records saved!\")\n",
    "        else:\n",
    "            print(\"\\nNo data downloaded.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SYNC COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print('Functions loaded successfully. Ready to run!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sync\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
